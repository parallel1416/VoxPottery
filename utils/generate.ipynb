{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb446c6-8dc2-43de-a749-59e37acbab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from visualize import *\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, resolution=64):\n",
    "        super.init()\n",
    "        # initialize superior inherited class, necessary hyperparams and modules\n",
    "        # You may use torch.nn.Conv3d(), torch.nn.sequential(), torch.nn.BatchNorm3d() for blocks\n",
    "        # You may try different activation functions such as ReLU or LeakyReLU.\n",
    "        # REMENBER YOU ARE WRITING A DISCRIMINATOR (binary classification) so Sigmoid\n",
    "        # Dele return in __init__\n",
    "        # TODO\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Try to connect all modules to make the model operational!\n",
    "        # Note that the shape of x may need adjustment\n",
    "        # # Do not forget the batch size in x.dim\n",
    "        # TODO\n",
    "        return out\n",
    "        \n",
    "    \n",
    "class Generator(torch.nn.Module):\n",
    "    # TODO\n",
    "    def __init__(self, cube_len=64, z_latent_space=64, z_intern_space=64):\n",
    "        # similar to Discriminator\n",
    "        # Despite the blocks introduced above, you may also find torch.nn.ConvTranspose3d()\n",
    "        # Dele return in __init__\n",
    "        # TODO\n",
    "        return\n",
    "\n",
    "    \n",
    "    def forward_encode(self, x):\n",
    "        return\n",
    "        \n",
    "\n",
    "    def forward_decode(self, x):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # you may also find torch.view() useful\n",
    "        # we strongly suggest you to write this method seperately to forward_encode(self, x) and forward_decode(self, x)   \n",
    "        return out\n",
    "    \n",
    "\n",
    "def posprocessing(fake, mesh_frag):\n",
    "    # fake is the generated M*M*(1 or 4) output, try to recover a voxel from it \n",
    "    # design by yourself or you can also choose to ignore this function\n",
    "    return \n",
    "\n",
    "\n",
    "# You can implement the below two functions to load checkpoints and visualize .vox files. Option choice\n",
    "\n",
    "# define available_device\n",
    "\n",
    "def load_generator(path_checkpoint):\n",
    "    ## for evaluation?\n",
    "    G_encode_decode = Generator().to(available_device) #  hyperparams need to be implemented\n",
    "    checkpoint = torch.load(path_checkpoint, map_location=available_device)\n",
    "    G_encode_decode.load_state_dict(checkpoint)\n",
    "    G_encode_decode = G_encode_decode.eval()\n",
    "\n",
    "    return G_encode_decode\n",
    "\n",
    "\n",
    "def generate(model, vox_frag):\n",
    "    '''\n",
    "    generate model, doesn't guaruantee 100% correct\n",
    "    '''\n",
    "    mesh_frag = torch.Tensor(vox_frag).unsqueeze(0).float().to(available_device)\n",
    "    output_g_encode = model.forward_encode(mesh_frag)\n",
    "    fake = model.forward_decode(output_g_encode)\n",
    "    fake = fake + (mesh_frag.unsqueeze(1))\n",
    "    fake = fake.detach().cpu().numpy()\n",
    "    mesh_frag = mesh_frag.detach().cpu().numpy()\n",
    "    return fake, mesh_frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09a036c-f9de-4ef4-9f27-f90f985770f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda\n",
      "<torch.cuda.device object at 0x000001A3A9B4AA40>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    available_device=torch.device(\"cuda\")\n",
    "else:\n",
    "    available_device=torch.device(\"cpu\")\n",
    "print(torch.cuda.device_count())\n",
    "print(available_device)\n",
    "print(torch.cuda.device(0))\n",
    " # Last part will be different\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76c0ac-ee65-493e-aeed-3b4c728bba9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
